#!/usr/bin/env python3
"""
åˆ†æè¯ä¹¦ä¿¡æ¯å†…å®¹ï¼Œå¸®åŠ©æ”¹è¿›åˆ†ç±»ç®—æ³•
"""

import requests
import pandas as pd

def analyze_current_data():
    """åˆ†æå½“å‰æ•°æ®åº“ä¸­çš„è¯ä¹¦ä¿¡æ¯"""
    response = requests.get('http://localhost:8000/api/talents/')
    if response.status_code != 200:
        print("âŒ æ— æ³•è·å–æ•°æ®")
        return
    
    talents = response.json().get('talents', [])
    
    print("ğŸ“‹ è¯ä¹¦ä¿¡æ¯è¯¦ç»†åˆ†æ")
    print("=" * 80)
    
    # æŒ‰åˆ†ç±»çŠ¶æ€åˆ†ç»„
    classified = []
    unclassified = []
    
    for talent in talents:
        cert_info = talent.get('certificate_info', '')
        level = talent.get('certificate_level')
        specialty = talent.get('certificate_specialty')
        social = talent.get('social_security_status')
        
        if level or specialty or social:
            classified.append(talent)
        else:
            unclassified.append(talent)
    
    print(f"âœ… å·²åˆ†ç±»: {len(classified)} äºº")
    print(f"â“ æœªåˆ†ç±»: {len(unclassified)} äºº")
    
    print("\nğŸ” æœªåˆ†ç±»äººå‘˜çš„è¯ä¹¦ä¿¡æ¯:")
    print("-" * 80)
    for i, talent in enumerate(unclassified):
        cert_info = talent.get('certificate_info', '')
        comm_content = talent.get('communication_content', '')
        print(f"{i+1}. {talent['name']}")
        print(f"   è¯ä¹¦ä¿¡æ¯: {cert_info}")
        if comm_content and comm_content != cert_info:
            print(f"   æ²Ÿé€šå†…å®¹: {comm_content}")
        print()
    
    print("\nğŸ¯ å·²åˆ†ç±»äººå‘˜æ ·æœ¬:")
    print("-" * 80)
    for i, talent in enumerate(classified[:10]):
        cert_info = talent.get('certificate_info', '')
        level = talent.get('certificate_level', 'æœªçŸ¥')
        specialty = talent.get('certificate_specialty', 'æœªçŸ¥')
        social = talent.get('social_security_status', 'æœªçŸ¥')
        print(f"{i+1}. {talent['name']} - ç­‰çº§:{level} ä¸“ä¸š:{specialty} ç¤¾ä¿:{social}")
        print(f"   åŸæ–‡: {cert_info}")
        print()

def analyze_excel_data():
    """åˆ†æExcelåŸå§‹æ•°æ®"""
    try:
        df = pd.read_excel('æ„å‘å®¢æˆ·è¡¨.xlsx')
        print("\nğŸ“Š ExcelåŸå§‹æ•°æ®åˆ†æ")
        print("=" * 80)
        
        # åˆ†æè¯ä¹¦ä¿¡æ¯åˆ—
        cert_column = df.iloc[:, 3] if len(df.columns) > 3 else None
        if cert_column is not None:
            print("ğŸ” è¯ä¹¦ä¿¡æ¯æ ·æœ¬:")
            print("-" * 40)
            
            unique_certs = cert_column.dropna().unique()
            for i, cert in enumerate(unique_certs[:15]):
                print(f"{i+1}. {cert}")
            
            print(f"\næ€»å…± {len(unique_certs)} ç§ä¸åŒçš„è¯ä¹¦ä¿¡æ¯")
            
            # å…³é”®è¯åˆ†æ
            all_text = ' '.join(cert_column.dropna().astype(str))
            
            level_keywords = {
                'ä¸€å»º': all_text.count('ä¸€å»º'),
                'ä¸€çº§å»ºé€ å¸ˆ': all_text.count('ä¸€çº§å»ºé€ å¸ˆ'),
                'äºŒå»º': all_text.count('äºŒå»º'),
                'äºŒçº§å»ºé€ å¸ˆ': all_text.count('äºŒçº§å»ºé€ å¸ˆ'),
                'è€ƒä¸€å»º': all_text.count('è€ƒä¸€å»º'),
                'å¤‡è€ƒä¸€å»º': all_text.count('å¤‡è€ƒä¸€å»º')
            }
            
            specialty_keywords = {
                'æˆ¿å»º': all_text.count('æˆ¿å»º'),
                'å»ºç­‘': all_text.count('å»ºç­‘'),
                'å¸‚æ”¿': all_text.count('å¸‚æ”¿'),
                'æœºç”µ': all_text.count('æœºç”µ'),
                'å…¬è·¯': all_text.count('å…¬è·¯'),
                'æ°´åˆ©': all_text.count('æ°´åˆ©'),
                'çŸ¿ä¸š': all_text.count('çŸ¿ä¸š')
            }
            
            social_keywords = {
                'ç¤¾ä¿': all_text.count('ç¤¾ä¿'),
                'ä¸é…åˆ': all_text.count('ä¸é…åˆ'),
                'æ— ç¤¾ä¿': all_text.count('æ— ç¤¾ä¿'),
                'å”¯ä¸€ç¤¾ä¿': all_text.count('å”¯ä¸€ç¤¾ä¿')
            }
            
            print("\nğŸ“ˆ å…³é”®è¯é¢‘ç‡ç»Ÿè®¡:")
            print("ç­‰çº§å…³é”®è¯:")
            for keyword, count in level_keywords.items():
                if count > 0:
                    print(f"  {keyword}: {count}æ¬¡")
            
            print("ä¸“ä¸šå…³é”®è¯:")
            for keyword, count in specialty_keywords.items():
                if count > 0:
                    print(f"  {keyword}: {count}æ¬¡")
            
            print("ç¤¾ä¿å…³é”®è¯:")
            for keyword, count in social_keywords.items():
                if count > 0:
                    print(f"  {keyword}: {count}æ¬¡")
                    
    except Exception as e:
        print(f"âŒ åˆ†æExcelæ•°æ®å¤±è´¥: {e}")

def suggest_improvements():
    """å»ºè®®æ”¹è¿›æ–¹æ¡ˆ"""
    print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    print("=" * 80)
    print("1. è¯ä¹¦ç­‰çº§è¯†åˆ«:")
    print("   - æ·»åŠ æ›´å¤šä¸€å»ºç›¸å…³å…³é”®è¯: 'è€ƒä¸€å»º', 'å¤‡è€ƒä¸€å»º', 'å¢é¡¹', 'ä¸€çº§'")
    print("   - å¤„ç†å¤åˆæè¿°: 'äºŒå»ºè½¬ä¸€å»º', 'äºŒå»ºè€ƒä¸€å»º'")
    
    print("\n2. è¯ä¹¦ä¸“ä¸šè¯†åˆ«:")
    print("   - æ·»åŠ ç®€ç§°æ˜ å°„: 'æˆ¿å»º'â†’'å»ºç­‘å·¥ç¨‹'")
    print("   - å¤„ç†å¤šä¸“ä¸š: 'åŒä¸“ä¸š', 'æœºç”µ+å¸‚æ”¿'")
    
    print("\n3. ç¤¾ä¿æƒ…å†µè¯†åˆ«:")
    print("   - æ‰©å±•å…³é”®è¯: 'ç¤¾ä¿å…¬ç§¯é‡‘', 'é…åˆç¤¾ä¿'")
    print("   - åœ°åŸŸä¿¡æ¯: 'åœ¨äº‘å—æœ‰ç¤¾ä¿'")
    
    print("\n4. ä»·æ ¼ä¿¡æ¯æå–:")
    print("   - ä»·æ ¼æ¨¡å¼: 'æŒ‚äº†2w', 'æŠ¥ä»·3.5', 'ä»·æ ¼2.2'")
    print("   - å•ä½è½¬æ¢: ä¸‡å…ƒè½¬æ¢ä¸ºå…·ä½“æ•°å­—")
    
    print("\n5. åˆ°æœŸæ—¶é—´æå–:")
    print("   - æ—¶é—´æ¨¡å¼: '11æœˆåˆ°æœŸ', '9æœˆä»½åˆ°æœŸ', '25å¹´9æœˆ'")

if __name__ == "__main__":
    analyze_current_data()
    analyze_excel_data()
    suggest_improvements()
